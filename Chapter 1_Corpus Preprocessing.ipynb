{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import numpy as np\n",
    "! pip show anthropic\n",
    "! pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "ANTHROPIC_API_KEY=\"API_KEY\"\n",
    "OPENAI_API_KEY=\"API_KEY\"\n",
    "\n",
    "# Set your own IP to allow access\n",
    "proxy_url = 'http://----'\n",
    "proxy_port = 'xxxx' \n",
    "\n",
    "os.environ['http_proxy'] = f'{proxy_url}:{proxy_port}'\n",
    "os.environ['https_proxy'] = f'{proxy_url}:{proxy_port}'\n",
    "\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#API Usage\n",
    "client_claude = anthropic.Anthropic(api_key= ANTHROPIC_API_KEY)\n",
    "client_emb = OpenAI(api_key = OPENAI_API_KEY)\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    return client_emb.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# Define chatbot\n",
    "def chat_with_claude_sonnet(prompt,system_prompt):\n",
    "    messages = [{\"role\": \"user\",\"content\": prompt}]\n",
    "    response = client_claude.messages.create(\n",
    "        model=\"claude-3-sonnet-20240229\",\n",
    "        max_tokens=4096,\n",
    "        temperature=0.5,\n",
    "        system=system_prompt,\n",
    "        messages=messages\n",
    "    )\n",
    "    message = response.content[0].text\n",
    "\n",
    "    return message\n",
    "\n",
    "def chat_with_claude_opus(prompt,system_prompt):\n",
    "    messages = [{\"role\": \"user\",\"content\": prompt}]\n",
    "    response = client_claude.messages.create(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        max_tokens=4000,\n",
    "        temperature=0.5,\n",
    "        system=system_prompt,\n",
    "        messages=messages\n",
    "    )\n",
    "    message = response.content[0].text\n",
    "\n",
    "    return message\n",
    "\n",
    "def chat_with_claude_haiku(prompt,system_prompt):\n",
    "    messages = [{\"role\": \"user\",\"content\": prompt}]\n",
    "    response = client_claude.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=4000,\n",
    "        temperature=0.5,\n",
    "        system=system_prompt,\n",
    "        messages=messages\n",
    "    )\n",
    "    message = response.content[0].text\n",
    "\n",
    "    return message\n",
    "\n",
    "def chat_with_openai(prompt, system_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabidopsis phenotype acquisition\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Input table paragraphs by line\n",
    "with open(\"Path/Focus on phenotype.txt\",\"r\",encoding = \"utf-8\") as f:\n",
    "    str_file = f.readlines()\n",
    "    \n",
    "systemt_prompt = \"\"\"Please extract the plant phenotype based on the input content. If there is none, please reply \"None\" \"\"\"\n",
    "\n",
    "results = []  # List to store the results\n",
    "\n",
    "# Open a new TXT file to write the results\n",
    "with open(\"Path/phenotype_output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for content in tqdm(str_file, desc=\"Processing\"):\n",
    "        prompt = \"Input:\" + content\n",
    "        \n",
    "        retry_count = 0\n",
    "        while retry_count < 3:\n",
    "            try:\n",
    "                result = chat_with_claude_sonnet(prompt, systemt_prompt)\n",
    "                results.append(result)\n",
    "                \n",
    "                # Write each result to a TXT file\n",
    "                file.write(f\"Input:{content}\\n\")\n",
    "                file.write(f\"Result:{result}\\n\")\n",
    "                file.write(\"-\" * 50 + \"\\n\")  # Add separator line\n",
    "                \n",
    "                break  # If the request is successful, exit the loop\n",
    "            except AnthropicError as e:\n",
    "                if 'overloaded_error' in str(e):\n",
    "                    retry_count += 1\n",
    "                    print(f\"Overloaded error occurred. Retrying... (Attempt {retry_count}/3)\")\n",
    "                    time.sleep(5)  # Wait 5 seconds and try again\n",
    "                else:\n",
    "                    raise e  # If it is any other error, throw an exception\n",
    "        else:\n",
    "            # If the number of retries reaches 3, write the request failure information to the TXT file\n",
    "            file.write(f\"Input:{content}\\n\")\n",
    "            file.write(\"Result:Request failed\\n\")\n",
    "            file.write(\"-\" * 50 + \"\\n\")  # Add separator line\n",
    "            print(\"Failed to get response after 3 retries.\")\n",
    "    \n",
    "    # Output results\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i+1}:{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get phenotypic response corpus from Claude Opus\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Input table paragraphs by line\n",
    "with open(\"Path/phenotype_output.txt\",\"r\",encoding = \"utf-8\") as f:\n",
    "    output_file = f.readlines()\n",
    "\n",
    "systemt_prompt = \"\"\"Please complete the following tasks based on the input:\n",
    "\n",
    "1: Return the genes in Arabidopsis that are related to the phenotype\n",
    "2: List all other genes or proteins related to the gene in 1\n",
    "3: Describe other phenotypes associated with the genes or proteins in 1 and 2\n",
    "4: Describe the results of existing published articles related to the conclusions in 1, 2, and 3\n",
    "5: Perform a logical analysis of the results in 4\n",
    "6: List homologous genes in crops with important economic value such as rice, wheat, and corn\n",
    "\n",
    "Note: Use concise language to reply, without adding any empty words! ! ! ! \"\"\"\n",
    "\n",
    "results = []  # List to store the results\n",
    "\n",
    "# Open a new TXT file to write the results\n",
    "with open(\"Path/phenotype_output_answer.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for content in tqdm(output_file, desc=\"Processing\"):\n",
    "        prompt = \"Input:\" + content\n",
    "        \n",
    "        retry_count = 0\n",
    "        while retry_count < 5:\n",
    "            try:\n",
    "                result = chat_with_claude_opus(prompt, systemt_prompt)\n",
    "                results.append(result)\n",
    "                \n",
    "                # Write each result to a TXT file\n",
    "                file.write(f\"Input:{content}\\n\")\n",
    "                file.write(f\"Results:{result}\\n\")\n",
    "                file.write(\"-\" * 50 + \"\\n\")  # Add separator line\n",
    "                \n",
    "                break  # If the request is successful, exit the loop\n",
    "            except AnthropicError as e:\n",
    "                if 'overloaded_error' in str(e):\n",
    "                    retry_count += 1\n",
    "                    print(f\"Overloaded error occurred. Retrying... (Attempt {retry_count}/5)\")\n",
    "                    time.sleep(5)  # Wait 5 seconds and try again\n",
    "                else:\n",
    "                    raise e  # If it is any other error, throw an exception\n",
    "        else:\n",
    "            # If the number of retries reaches 5, write the request failure information to the TXT file\n",
    "            file.write(f\"Input:{content}\\n\")\n",
    "            file.write(\"Extract result: Request failed\\n\")\n",
    "            file.write(\"-\" * 50 + \"\\n\")  # Add separator line\n",
    "            print(\"Failed to get response after 5 retries.\")\n",
    "    \n",
    "    # Output results\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i+1}:{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "systemt_prompt = \"\"\"\n",
    "Based on the following gene information, please generate the following types of question-answer pairs and answer them:\n",
    "\n",
    "1. Basic information query - about gene ID and alias\n",
    "2. Functional explanation - explain the function of the gene\n",
    "3. Relationship query - ask about genes belonging to the same protein family\n",
    "4. Complex query - about the relationship between genes and specific biological processes\n",
    "5. Inference question - speculate on the biological process that the gene may be involved in based on known information\n",
    "\n",
    "For each type, generate at least one question-answer pair. Make sure the answer is based only on the information provided, and do not add information that is not given. If the information is not enough to answer a certain type of question, you can skip that type.\n",
    "Please output in the following format:\n",
    "\n",
    "Q: [Question]\n",
    "A: [Answer]\n",
    "\"\"\"\n",
    "\n",
    "def process_file(input_file_path, output_file_path):\n",
    "    start_time = time.time()  # Record start time\n",
    "    \n",
    "    if not output_file_path.lower().endswith('.txt'):\n",
    "        output_file_path += '.txt'\n",
    "    \n",
    "    # Get the total number of rows\n",
    "    with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        total_lines = sum(1 for line in f if line.strip())\n",
    "    \n",
    "    processed_lines = 0\n",
    "    last_update_time = start_time\n",
    "    \n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        with open(input_file_path, \"r\", encoding=\"utf-8\") as input_file:\n",
    "            for line in input_file:\n",
    "                line = line.strip()  \n",
    "                if line:  \n",
    "                    retry_count = 0\n",
    "                    while retry_count < 3:\n",
    "                        try:\n",
    "                            result = chat_with_claude_sonnet(line, systemt_prompt)\n",
    "                            \n",
    "                            output_file.write(f\"Input: {line}\\n\")\n",
    "                            output_file.write(f\"Output:\\n{result}\\n\")\n",
    "                            output_file.write(\"\\n\")  # Add separator\n",
    "                            \n",
    "                            processed_lines += 1\n",
    "                            current_time = time.time()\n",
    "                            \n",
    "                            # Update progress every 5 seconds or every 10 rows processed\n",
    "                            if current_time - last_update_time > 5 or processed_lines % 10 == 0:\n",
    "                                progress = processed_lines / total_lines * 100\n",
    "                                elapsed_time = current_time - start_time\n",
    "                                time_per_line = elapsed_time / processed_lines if processed_lines > 0 else 0\n",
    "                                \n",
    "                                print(f\"Progress: {progress:.2f}% ({processed_lines}/{total_lines}), \"\n",
    "                                      f\"Speed: {time_per_line:.2f} s/line\")\n",
    "                                last_update_time = current_time\n",
    "                            \n",
    "                            break  # If the request is successful, exit the retry loop\n",
    "                        except Exception as e:\n",
    "                            print(f\"Request failed, error message: {str(e)}\")\n",
    "                            retry_count += 1\n",
    "                            if retry_count < 3:\n",
    "                                print(f\"Wait 5 seconds and try again, number of retries: {retry_count}\")\n",
    "                                time.sleep(5) \n",
    "                            else:\n",
    "                                print(\"The number of retries exceeds the limit, skipping the request\")\n",
    "    \n",
    "    end_time = time.time()  # Record end time\n",
    "    process_time = end_time - start_time  # Calculate processing time\n",
    "    return process_time\n",
    "\n",
    "input_file_path = \"Path/Gene ID.txt\"\n",
    "output_file_path = \"Path/Answer\"\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "print(f\"Processing File: {os.path.basename(input_file_path)}\")\n",
    "process_time = process_file(input_file_path, output_file_path)\n",
    "print(f\"File processing completed, time {process_time:.2f} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
